<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>GitLab.runner</title>
    <link rel="icon" href="https://sempernow.github.io/refpages/sa/favicon.png">
    <link rel="stylesheet" href="https://sempernow.github.io/refpages/sa/css/normalize.css">
    <link rel="stylesheet" href="https://sempernow.github.io/refpages/sa/css/main.css">
    <!--
    <link rel="stylesheet" href="https://sempernow.github.io/refpages/sa/css/dev.css">
    -->
    <link rel="stylesheet" href="https://sempernow.github.io/refpages/sa/css/hljs.github.min.css">
    <style>

    </style>
    <script src="https://sempernow.github.io/refpages/sa/js/hl.min.js"></script>
    <script>hljs.highlightAll()</script>
</head>
<body>
    <main>
        <h1><a href="https://docs.gitlab.com/runner/">GitLab Runner</a> | <a href="https://gitlab.com/gitlab-org/gl-openshift/gitlab-runner-operator" title="gitlab.com">Operator</a></h1>

<h2>Q:</h2>

<p>How to configure custom <code>cache_dir</code> of <code>gitlab-runner</code> if it's a kubernetes executor</p>

<h2>A:</h2>

<p>Here's the <strong>complete, consolidated configuration</strong> to properly set up a custom cache directory with correct permissions in your GitLab Kubernetes runner:</p>

<h3>1. Final <code>config.toml</code> Configuration</h3>

<pre><code class="language-toml">[[runners]]
  name = &quot;kubernetes-runner&quot;
  url = &quot;https://gitlab.example.com&quot;
  token = &quot;YOUR_RUNNER_TOKEN&quot;
  executor = &quot;kubernetes&quot;
  cache_dir = &quot;/mnt/cache&quot;  # Your custom cache path
  
  # Critical permission settings
  [runners.kubernetes.pod_security_context]
    fs_group = 1000         # Ensures write permission for gitlab-runner
    run_as_user = 1000      # Default gitlab-runner user
    run_as_group = 1000     # Default gitlab-runner group
  
  # PVC Mount (replace with your existing PVC name)
  [runners.kubernetes]
    [[runners.kubernetes.volumes.pvc]]
      name = &quot;gitlab-runner-cache&quot;  # Must match your PVC name
      mount_path = &quot;/mnt/cache&quot;     # Must match cache_dir
</code></pre>

<h3>2. Required Kubernetes Resources</h3>

<pre><code class="language-yaml"># PVC Definition (if not existing)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gitlab-runner-cache  # ← Must match config.toml
spec:
  accessModes:
    - ReadWriteMany          # Critical for cache functionality
  resources:
    requests:
      storage: 10Gi         # Adjust size as needed
  storageClassName: standard # Match your storage class
</code></pre>

<h3>3. Verification Checklist</h3>

<ol>
<li><p><strong>PVC Exists and is Bound</strong>:</p>

<pre><code class="language-bash">kubectl get pvc gitlab-runner-cache
</code></pre>

<p>Should show STATUS=Bound</p></li>

<li><p><strong>Correct Permissions</strong>:</p>

<pre><code class="language-bash">kubectl exec -it &lt;runner-pod&gt; -- ls -ld /mnt/cache
</code></pre>

<p>Should show:</p>

<pre><code>drwxrwsr-x 2 1000 1000 4096 ...
</code></pre>

<p>(The 's' in group permissions indicates working setgid)</p></li>

<li><p><strong>Write Test</strong>:</p>

<pre><code class="language-bash">kubectl exec -it &lt;runner-pod&gt; -- \
 sh -c &quot;touch /mnt/cache/testfile &amp;&amp; ls -l /mnt/cache/testfile&quot;
</code></pre></li>
</ol>

<h3>Key Takeaways</h3>

<ol>
<li><p><strong>Four Critical Elements</strong>:</p>

<ul>
<li><code>cache_dir</code> in <code>[[runners]]</code></li>
<li>Matching PVC <code>mount_path</code></li>
<li><code>pod_security_context</code> with <code>fs_group</code></li>
<li>PVC with <code>ReadWriteMany</code> access</li>
</ul></li>

<li><p><strong>Permission Flow</strong>:</p>

<pre><code class="language-mermaid">graph TD
 A[PVC Storage] --&gt;|inherits| B[PV Permissions]
 B --&gt;|modified by| C[Pod fs_group]
 C --&gt;|applied to| D[/mnt/cache]
 D --&gt;|used by| E[GitLab Runner]
</code></pre></li>

<li><p><strong>Troubleshooting Tip</strong>:
If files still appear as root-owned, add this to your jobs:</p>

<pre><code class="language-yaml">variables:
 FF_KUBERNETES_HONOR_ENTRYPOINT: &quot;1&quot;  # Ensures pod user context is respected
</code></pre></li>
</ol>

<h2>Q:</h2>

<p>Regarding RBAC, if a GitLab runner is deployed into K8s cluster under its own namespace, and the CI/CD has <code>kubectl</code> that deploys app to cluster, what <code>Role</code>s must it have for pipelines to <strong>deploy to any declared namespace</strong>?</p>

<h2>A:</h2>

<p>To allow a GitLab Runner deployed into a Kubernetes cluster under its own namespace to deploy applications across multiple namespaces using <code>kubectl</code> in GitLab CI/CD pipelines, you'll need to set up appropriate RBAC (Role-Based Access Control) permissions. Here's a step-by-step guide on configuring these permissions:</p>

<h3>1. Create a Service Account</h3>

<p>First, create a Service Account in the GitLab Runner's namespace that the runner will use to interact with the Kubernetes API.</p>

<pre><code class="language-yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitlab-runner
  namespace: gitlab-runner-namespace
</code></pre>

<h3>2. Define ClusterRole</h3>

<p>You need a <code>ClusterRole</code> that grants the permissions needed to deploy resources to any namespace. This role typically includes permissions for managing deployments, statefulsets, pods, services, configmaps, and other relevant resources across all namespaces.</p>

<pre><code class="language-yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: deployment-manager
rules:
- apiGroups: [&quot;&quot;, &quot;apps&quot;, &quot;batch&quot;, &quot;extensions&quot;, &quot;networking.k8s.io&quot;]
  resources: [&quot;deployments&quot;, &quot;replicasets&quot;, &quot;pods&quot;, &quot;services&quot;, &quot;configmaps&quot;, &quot;secrets&quot;, &quot;persistentvolumeclaims&quot;, &quot;ingresses&quot;, &quot;jobs&quot;, &quot;cronjobs&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]
- apiGroups: [&quot;autoscaling&quot;]
  resources: [&quot;horizontalpodautoscalers&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;create&quot;, &quot;update&quot;, &quot;delete&quot;]
</code></pre>

<ul>
<li><a href="https://docs.gitlab.com/runner/executors/kubernetes/#configure-runner-api-permissions">Configure runner API permissions</a></li>
</ul>

<h3>3. Bind ClusterRole to Service Account</h3>

<p>Create a <code>ClusterRoleBinding</code> that binds the <code>ClusterRole</code> to the Service Account created in step 1. This binding allows the GitLab Runner to manage resources in all namespaces.</p>

<pre><code class="language-yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gitlab-runner-deployment-manager
subjects:
- kind: ServiceAccount
  name: gitlab-runner
  namespace: gitlab-runner-namespace
roleRef:
  kind: ClusterRole
  name: deployment-manager
  apiGroup: rbac.authorization.k8s.io
</code></pre>

<h3>4. Configure GitLab CI/CD to Use the Service Account</h3>

<p>Ensure your GitLab CI/CD pipelines are configured to use the created Service Account. This is usually done by setting the <code>serviceAccountName</code> in the pod template for the GitLab Runner’s jobs.</p>

<pre><code class="language-yaml">serviceAccountName: gitlab-runner
</code></pre>

<h3>Additional Considerations</h3>

<ul>
<li><strong>Security</strong>: Providing broad permissions can pose security risks. Always adhere to the principle of least privilege by granting only the necessary permissions needed for the tasks.</li>
<li><strong>Namespace Management</strong>: If the deployments are sensitive or require strict separation, consider using more granular roles and bindings specific to each namespace rather than a single cluster-wide role.</li>
<li><strong>Secrets Management</strong>: Be cautious with permissions around secrets to prevent unauthorized access to sensitive information.</li>
</ul>

<p>This setup assumes that you're managing deployments across various namespaces and need a wide range of Kubernetes resource access. Adjust the resources and verbs according to your specific CI/CD requirements.</p>

<h2>Q:</h2>

<p>How to scope a runner to a group or project and register it, if its deployed on K8s and via Helm chart?</p>

<h2>A:</h2>

<p>To scope a GitLab Runner to a specific group or project, you can <strong>register the runner with that particular group or project</strong>. This scoping <strong>ensures that the runner only picks up jobs from the group or project it's associated with</strong>, which can help manage resources and permissions effectively, especially in <strong>environments with multiple teams or projects</strong>. Here’s how you can do it:</p>

<h3>Registering a Runner to a Project</h3>

<ol>
<li><p><strong>Go to the Project’s Settings</strong>:</p>

<ul>
<li>Navigate to your project in GitLab.</li>
<li>Click on <strong>Settings</strong> &gt; <strong>CI/CD</strong> and expand the <strong>Runners</strong> section.</li>
</ul></li>

<li><p><strong>Specific Runners</strong>:</p>

<ul>
<li>In the <strong>Runners</strong> section, you’ll see a description of how to register a new runner specifically for this project. This includes a unique registration token for the project.</li>
</ul></li>
</ol>

<p>To scope a GitLab Runner installed via a Helm chart to a specific group or project, you need to register the runner with specific registration tokens from either the group or project level rather than using the instance-wide registration token. Here's how you can achieve this:</p>

<h3>Step 1: Obtain the Registration Token</h3>

<p>First, you need to get the registration token from the GitLab group or project you want to scope the runner to:</p>

<ul>
<li><p><strong>For a Group:</strong></p>

<ol>
<li>Go to your group’s homepage on GitLab.</li>
<li>Click on <strong>Settings</strong> &gt; <strong>CI/CD</strong>.</li>
<li>Expand the <strong>Runners</strong> section to find the registration token.</li>
</ol></li>

<li><p><strong>For a Project:</strong></p>

<ol>
<li>Go to your project’s homepage on GitLab.</li>
<li>Click on <strong>Settings</strong> &gt; <strong>CI/CD</strong>.</li>
<li>Expand the <strong>Runners</strong> section to find the registration token.</li>
</ol></li>
</ul>

<h3>Step 2: Configure the Helm Values</h3>

<p>Modify the <code>values.yaml</code> file used for deploying the GitLab Runner Helm chart to include this registration token. Ensure you also set the <code>runnerRegistrationToken</code> to the token you retrieved from the group or project:</p>

<pre><code class="language-yaml">gitlabUrl: https://gitlab.example.com/
runnerRegistrationToken: &quot;PROJECT_OR_GROUP_REGISTRATION_TOKEN&quot;

## For runners scoped to a specific project or group
runners:
  ## Register the runner to the specific project or group
  tags: &quot;group-specific,example&quot;
  locked: true  # Set to 'true' to lock the runner to the current project/group

## Other configuration as required...
</code></pre>

<p>In this configuration:
- <code>gitlabUrl</code> should be set to your GitLab instance URL.
- <code>runnerRegistrationToken</code> is the token you obtained from your GitLab group or project settings.
- <code>tags</code> can be used to specify specific runner tags which help in assigning jobs to this runner.
- Setting <code>locked: true</code> ensures the runner is locked to the project or group (only available at the project level).</p>

<h3>Step 3: Install/Upgrade the Runner</h3>

<p>If you are installing the runner for the first time, use the following command:</p>

<pre><code class="language-bash">helm install my-runner-name gitlab/gitlab-runner -f values.yaml
</code></pre>

<p>If you already have a runner installed and need to reconfigure or update it:</p>

<pre><code class="language-bash">helm upgrade my-runner-name gitlab/gitlab-runner -f values.yaml
</code></pre>

<p>This setup will register the runner with GitLab scoped to the specific project or group using the registration token from that level. By using the registration token from a specific group or project, the runner will automatically be associated and locked to that scope, assuming <code>locked</code> is set appropriately in the values.</p>

<h3>Additional Considerations</h3>

<ul>
<li><strong>Namespace</strong>: Make sure that the runner is installed in the appropriate Kubernetes namespace if you are using Kubernetes namespaces for logical separation between projects or environments.</li>
<li><strong>Executor Type</strong>: When registering the runner, choose an executor that matches your environment and needs (e.g., Docker for container-based builds, Kubernetes for clusters, etc.).</li>
<li><strong>Tags</strong>: Tags can be used to control job assignment further. Jobs can specify tags to determine which runner should pick them up.</li>
<li><strong>Concurrent Jobs</strong>: If your runner is expected to handle multiple jobs, configure its concurrency settings accordingly.</li>
<li><strong>Security</strong>: Be careful with the scope of permissions and access that your runner has, especially in shared environments. Ensure it only has access to necessary resources.</li>
</ul>

<p>By scoping runners to specific projects or groups, you can better manage access, improve security, and optimize resource utilization in your CI/CD workflows.</p>

<h2>Q:</h2>

<p>Is it advised to have a runner per namespace, and so Role and Rolebinding would suffice instead of Cluster equivalents.</p>

<h2>A:</h2>

<p>Yes, using a separate GitLab Runner per namespace with corresponding Role and RoleBinding, rather than a ClusterRole and ClusterRoleBinding, is often advised, especially when dealing with a multi-tenant Kubernetes environment or when you want to enforce strict isolation and security policies between different projects or teams. This approach aligns with the principle of least privilege, ensuring that the runner has only the necessary permissions within a specific namespace.</p>

<h3>Advantages of Using Role and RoleBinding Per Namespace</h3>

<p><strong>1. Security and Isolation:</strong> By restricting a runner to a specific namespace, you ensure that it can only access resources within that namespace. This prevents accidental or malicious access to resources in other parts of the cluster.</p>

<p><strong>2. Resource Management:</strong> Runners scoped to a namespace can be better tailored in terms of the resources they use (CPU, memory limits, etc.), which can improve scheduling efficiency and resource allocation.</p>

<p><strong>3. Access Control:</strong> It simplifies management of access controls, as you can directly apply policies relevant to the specific projects or teams using that namespace without affecting others.</p>

<p><strong>4. Organizational Clarity:</strong> It helps in maintaining clarity in CI/CD processes where different teams or projects have specific configurations, secrets, or environment setups that are not shared across the organization.</p>

<h3>How to Set Up Role and RoleBinding for a GitLab Runner</h3>

<p>You would typically proceed as follows to set up a GitLab Runner with a Role and RoleBinding scoped to a single namespace:</p>

<h4>Create the Service Account</h4>

<pre><code class="language-yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitlab-runner
  namespace: specific-namespace
</code></pre>

<h4>Define the Role</h4>

<p>This Role example gives permissions to manage pods and deployments within a specific namespace.</p>

<pre><code class="language-yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: specific-namespace
  name: gitlab-runner-role
rules:
- apiGroups: [&quot;&quot;, &quot;apps&quot;]
  resources: [&quot;pods&quot;, &quot;pods/exec&quot;, &quot;pods/portforward&quot;, &quot;deployments&quot;]
  verbs: [&quot;create&quot;, &quot;delete&quot;, &quot;get&quot;, &quot;list&quot;, &quot;patch&quot;, &quot;update&quot;, &quot;watch&quot;]
</code></pre>

<ul>
<li>See next Q/A (below) for broader access settings</li>
<li><a href="https://docs.gitlab.com/runner/executors/kubernetes/#configure-runner-api-permissions">Configure runner API permissions</a></li>
</ul>

<h4>Create a RoleBinding</h4>

<p>This binds the previously defined Role to the Service Account.</p>

<pre><code class="language-yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gitlab-runner-rolebinding
  namespace: specific-namespace
subjects:
- kind: ServiceAccount
  name: gitlab-runner
  namespace: specific-namespace
roleRef:
  kind: Role
  name: gitlab-runner-role
  apiGroup: rbac.authorization.k8s.io
</code></pre>

<h4>Configure GitLab Runner</h4>

<p>Make sure your GitLab CI configuration uses the service account and that the runner is configured to operate within the intended namespace.</p>

<h3>Considerations</h3>

<ul>
<li><strong>Scalability</strong>: While this approach is more secure, it might require more management overhead as the number of namespaces and runners increases.</li>
<li><strong>Complexity</strong>: Each runner's configuration and maintenance could become more complex, especially in dynamic environments with many microservices or frequent changes.</li>
<li><strong>Resource Utilization</strong>: Multiple runners might lead to underutilization of resources unless carefully managed.</li>
</ul>

<p>Implementing a GitLab Runner per namespace can be highly beneficial for organizations that require stringent security controls and resource isolation between projects or teams. However, this should be balanced with the operational complexity and overhead it might introduce.</p>

<h2>Q:</h2>

<p>What about the rest of the required roles in the cluster-wide advise earlier?</p>

<h2>A:</h2>

<p>For a namespace-scoped GitLab Runner using Role and RoleBinding, the scope of permissions would need to be adjusted to fit within the namespace while still providing sufficient privileges for typical CI/CD tasks. Here’s how you can adapt the broader cluster-wide permissions into a namespace-specific Role definition:</p>

<h3>Namespace-Specific Role Configuration</h3>

<p>This configuration includes permissions for handling typical Kubernetes objects that are required for most CI/CD operations within a namespace:</p>

<pre><code class="language-yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: specific-namespace
  name: gitlab-runner-role
rules:
- apiGroups: [&quot;&quot;, &quot;apps&quot;, &quot;batch&quot;, &quot;extensions&quot;, &quot;networking.k8s.io&quot;]
  resources: [&quot;deployments&quot;, &quot;replicasets&quot;, &quot;pods&quot;, &quot;services&quot;, &quot;configmaps&quot;, &quot;secrets&quot;, &quot;persistentvolumeclaims&quot;, &quot;ingresses&quot;, &quot;jobs&quot;, &quot;cronjobs&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]
- apiGroups: [&quot;autoscaling&quot;]
  resources: [&quot;horizontalpodautoscalers&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;create&quot;, &quot;update&quot;, &quot;delete&quot;]
</code></pre>

<ul>
<li><a href="https://docs.gitlab.com/runner/executors/kubernetes/#configure-runner-api-permissions">Configure runner API permissions</a></li>
<li>@ <code>values.yaml</code> : &quot;<code>rbac.create: true</code>&quot;, &quot;<code>rbac.rules: []</code>&quot;</li>
</ul>

<h3>Explanation of Roles</h3>

<ul>
<li><strong>Pods and Deployments</strong>: Essential for deploying and managing applications and their scaling.</li>
<li><strong>ReplicaSets</strong>: Necessary for managing the lifecycle of pods that are created by deployments.</li>
<li><strong>Services</strong>: Required for creating and managing network access to the pods, a common requirement in deployments.</li>
<li><strong>ConfigMaps and Secrets</strong>: Often used to manage configuration data and secrets for applications, respectively.</li>
<li><strong>PersistentVolumeClaims</strong>: For managing storage used by the pods.</li>
<li><strong>Ingresses</strong>: Important for managing external access to services within the namespace.</li>
<li><strong>Jobs and CronJobs</strong>: Useful for tasks like database migrations, batch jobs, or scheduled tasks that are part of application management.</li>
<li><strong>HorizontalPodAutoscalers</strong>: For applications that need to scale based on load or other metrics.</li>
</ul>

<h3>RoleBinding Configuration</h3>

<p>To apply these permissions, the Role must be bound to the Service Account used by the GitLab Runner:</p>

<pre><code class="language-yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gitlab-runner-rolebinding
  namespace: specific-namespace
subjects:
- kind: ServiceAccount
  name: gitlab-runner
  namespace: specific-namespace
roleRef:
  kind: Role
  name: gitlab-runner-role
  apiGroup: rbac.authorization.k8s.io
</code></pre>

<h3>Considerations for Namespace-Specific Roles</h3>

<ul>
<li><strong>Security</strong>: This approach minimizes the risk of impacting resources outside the designated namespace.</li>
<li><strong>Flexibility</strong>: It allows each team or project to have tailored CI/CD pipelines that align with their specific needs and constraints.</li>
<li><strong>Management</strong>: While more granular control is beneficial for security and organizational purposes, it also requires more detailed management of permissions and configurations.</li>
</ul>

<p>By defining a comprehensive Role as shown, you ensure that your GitLab Runner has all necessary permissions to perform typical CI/CD tasks within a specific namespace, maintaining both flexibility and security.</p>

<h1>Resource limits | <a href="https://docs.gitlab.com/runner/install/kubernetes/">GitLab Runner on K8s by Helm chart</a></h1>

<h2>Q:</h2>

<p>How and where to set resource limits <strong>on the ephemeral child pods</strong> of GitLab Runners where the pipelines actually run?</p>

<h2>A:</h2>

<p>For ephemeral child pods of GitLab Runners, resource limits can be set at multiple levels to ensure proper resource allocation and prevent overconsumption. These limits should be defined in the <strong>GitLab Runner configuration</strong> as well as in the <strong>Kubernetes namespace or policy level</strong>.</p>

<hr>

<h3><strong>1. Configure Resource Limits in GitLab Runner ConfigMap</strong></h3>

<p>GitLab Runner dynamically spawns Kubernetes pods for each job. Resource limits can be set in the runner's <strong>ConfigMap</strong> under <code>.spec.config.runnerRegistration.config.kubernetes</code>.</p>

<p>Edit the GitLab Runner <strong>ConfigMap</strong> in the namespace where your runner is deployed:</p>

<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: gitlab-runner
  namespace: gitlab
data:
  config.toml: |
    [[runners]]
      executor = &quot;kubernetes&quot;
      [runners.kubernetes]
        cpu_request = &quot;500m&quot;   # Minimum CPU requested
        cpu_limit = &quot;1000m&quot;    # Maximum CPU allowed
        memory_request = &quot;512Mi&quot;  # Minimum memory requested
        memory_limit = &quot;1024Mi&quot;   # Maximum memory allowed
</code></pre>

<ul>
<li>@ <code>values.yaml</code>, the <code>runners.config</code> key is the <code>config.toml</code></li>
</ul>

<p>Then, restart the runner:</p>

<pre><code class="language-sh">kubectl delete pod -n gitlab -l app=gitlab-runner
</code></pre>

<hr>

<h3><strong>2. Define Resource Limits in the Kubernetes <code>values.yaml</code> (for Helm deployments)</strong></h3>

<p>If you deployed GitLab Runner using Helm, set the resource limits in the <code>values.yaml</code> file:</p>

<pre><code class="language-yaml">runners:
  config: |
    [[runners]]
      name = &quot;gitlab-k8s-runner&quot;
      executor = &quot;kubernetes&quot;
      [runners.kubernetes]
        cpu_request = &quot;500m&quot;
        cpu_limit = &quot;1&quot;
        memory_request = &quot;512Mi&quot;
        memory_limit = &quot;1024Mi&quot;

</code></pre>

<ul>
<li>@ <a href="https://gitlab.com/gitlab-org/charts/gitlab-runner/blob/main/values.yaml"><code>values.yaml</code></a></li>

<li><p><a href="https://docs.gitlab.com/runner/configuration/advanced-configuration/#the-global-section">Advanced configuration : runners</a>
Then upgrade the deployment:</p>

<pre><code class="language-sh">helm upgrade --install gitlab-runner gitlab/gitlab-runner -f values.yaml
</code></pre></li>
</ul>

<hr>

<h3><strong>3. Use Kubernetes ResourceQuotas and LimitRanges (Namespace-Level Control)</strong></h3>

<p>To enforce constraints at the namespace level, define <code>ResourceQuota</code> and <code>LimitRange</code>:</p>

<ul>
<li><strong>ResourceQuota</strong> <strong>limits the total</strong> available resources <strong>per namespace</strong>.
Useful in multi-tenancy, when several users or teams share a cluster with a fixed number of nodes,
there is a concern that one team could use more than its fair share of resources.</li>
<li><strong>LimitRange</strong> sets <strong>default</strong> resource requests and limits per pod in the namespace.</li>
</ul>

<p>Create a <code>ResourceQuota</code>:</p>

<pre><code class="language-yaml">apiVersion: v1
kind: ResourceQuota
metadata:
  name: gitlab-runner-quota
  namespace: gitlab
spec:
  hard:
    requests.cpu: &quot;4&quot;
    requests.memory: &quot;4Gi&quot;
    limits.cpu: &quot;8&quot;
    limits.memory: &quot;8Gi&quot;
</code></pre>

<p>Create a <code>LimitRange</code>:</p>

<pre><code class="language-yaml">apiVersion: v1
kind: LimitRange
metadata:
  name: gitlab-runner-limits
  namespace: gitlab
spec:
  limits:
    - default:
        cpu: &quot;1000m&quot;
        memory: &quot;1024Mi&quot;
      defaultRequest:
        cpu: &quot;500m&quot;
        memory: &quot;512Mi&quot;
      type: Container
</code></pre>

<p>Apply them:</p>

<pre><code class="language-sh">kubectl apply -f resourcequota.yaml
kubectl apply -f limitrange.yaml
</code></pre>

<hr>

<h3><strong>4. Dynamic Overrides in <code>.gitlab-ci.yml</code></strong></h3>

<p>Pipeline jobs can request specific resources by using <strong>CI/CD variables</strong>:</p>

<pre><code class="language-yaml">test-job:
  script:
    - echo &quot;Running tests&quot;
  tags:
    - kubernetes
  variables:
    KUBERNETES_CPU_REQUEST: &quot;750m&quot;
    KUBERNETES_CPU_LIMIT: &quot;1500m&quot;
    KUBERNETES_MEMORY_REQUEST: &quot;768Mi&quot;
    KUBERNETES_MEMORY_LIMIT: &quot;2Gi&quot;
</code></pre>

<hr>

<h3><strong>Conclusion</strong></h3>

<ul>
<li><strong>Set default limits in GitLab Runner (<code>config.toml</code>)</strong>.</li>
<li><strong>Apply namespace-level restrictions (<code>ResourceQuota</code>, <code>LimitRange</code>)</strong> for better control.</li>
<li><strong>Allow per-job overrides in <code>.gitlab-ci.yml</code></strong> for flexibility.</li>
</ul>
 
    </main>

    <script src="https://sempernow.github.io/refpages/sa/js/base.js"></script>
    <script>
        ;(function(o, undefined){
            'use strict'
            window.addEventListener('load', () => {
                ;(() => {})//()
                ;(() => {})//()
                ;(() => { // FOO LAB
                    const log = o.log('foo')
                        ,main = o.css('MAIN')
                    log('foo')
                    o.toDOM(main, '<h1>TEST</h1>')
                })//()
            })
        })( (typeof window !== 'undefined') 
            && (window[__APP__] = window[__APP__] || {})
                || (typeof global !== 'undefined') 
                    && (global[__APP__] = global[__APP__] || {})
        );
    </script>
</body>
</html>
